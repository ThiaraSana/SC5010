{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D829oNcKJUvU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "from PIL import Image\n",
        "from time import time\n",
        "from zipfile import ZipFile\n",
        "import seaborn as sb\n",
        "import glob\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import skimage.io as io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Progress bar  and timer functions to monitor the progress of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def progress_bar(perc_comp):\n",
        "    '''\n",
        "    Takes float or int between 0 and 100. \n",
        "    '''\n",
        "    bar_width = 100\n",
        "    bar = '#' * int(perc_comp)\n",
        "    bar += '-' * (100-int(perc_comp)) + ' ' + str(int(perc_comp)) + '% complete'\n",
        "    if perc_comp < 100:\n",
        "        print (bar, end='\\r')\n",
        "    else:\n",
        "        print (bar)\n",
        "        \n",
        "def timer_func(func):\n",
        "    '''\n",
        "    This function shows the execution time of the function object passed\n",
        "    '''\n",
        "    def wrap_func(*args, **kwargs):\n",
        "        t1 = time()\n",
        "        result = func(*args, **kwargs)\n",
        "        t2 = time()\n",
        "        print(f'Function {func.__name__!r} executed in {(t2-t1):.4f}s')\n",
        "        return result\n",
        "    return wrap_func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load cleaned Label .csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_FOLDER = \"./data/train_images/\"\n",
        "\n",
        "traindata = pd.read_csv(\"./data/final.csv\")\n",
        "traindata.loc[:,'image'] = TRAIN_FOLDER + traindata['image']\n",
        "\n",
        "outputdir = './results/'\n",
        "\n",
        "if not os.path.exists(outputdir+\"/train_images/\"):\n",
        "    os.makedirs(outputdir+\"/train_images/\")\n",
        "\n",
        "original = './data/final.csv'\n",
        "target = './final.csv'\n",
        "shutil.copyfile(original, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Training Database was very large, hence after selecting the images we wanted to use during the analysis of the labels in the .csv file, we only extracted the images required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "member_list = traindata['image'].tolist()\n",
        "for i in member_list:\n",
        "    with ZipFile('./train_images.zip', 'r') as zipObj:\n",
        "        zipObj.extract(str(i[-18:]), path=\"./data/train_images/\", pwd=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load pretrained yolov5l model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\Common/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
            "YOLOv5  2022-4-22 torch 1.9.0 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "yolo = torch.hub.load('ultralytics/yolov5', 'yolov5l', pretrained=True) #Choose from yolov5n yolov5s yolov5m yolov5l yolov5x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cropping function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crop(model, im_file):\n",
        "    results = model([im_file])\n",
        "\n",
        "    results = results.pandas().xyxy[0]\n",
        "    try:\n",
        "        xmin, xmax, ymin, ymax = int(results.xmin.min()), int(results.xmax.max()), int(results.ymin.min()), int(results.ymax.max())\n",
        "        return Image.fromarray(cv2.cvtColor(cv2.imread(im_file), cv2.COLOR_BGR2RGB)[ymin:ymax][:,xmin:xmax]), results\n",
        "\n",
        "    except ValueError:\n",
        "        return Image.fromarray(cv2.cvtColor(cv2.imread(im_file), cv2.COLOR_BGR2RGB)), pd.DataFrame()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######---------------------------------------------------------------------------------------------- 6% complete\r"
          ]
        }
      ],
      "source": [
        "t1 = time()\n",
        "train_annotations = pd.DataFrame()\n",
        "for i in range(len(traindata.image.values)):\n",
        "    output = outputdir+\"/train_images/\"+traindata.species.values[i]+\"/\"+traindata.image.values[i].split('/')[-1]\n",
        "    img, df = crop(yolo, traindata.image.values[i])\n",
        "    img = T.functional.center_crop(img, (max(img.size),max(img.size)))\n",
        "    img = T.functional.resize(img,size=(224,224))\n",
        "    if len(df)>0:    \n",
        "        train_annotations = train_annotations.append(pd.DataFrame(df.values,\n",
        "                            columns=['xmin', 'ymin', 'xmax', 'ymax', 'conf', 'class', 'name'], \n",
        "                            index=[traindata.image.values[i]]*len(df)))\n",
        "    else:    \n",
        "        train_annotations = train_annotations.append(pd.DataFrame(df.values,\n",
        "                            ))\n",
        "    img.save(output)\n",
        "    progress_bar(i/(len(traindata.image.values)-1)*100)   \n",
        "t2 = time()\n",
        "print(f'Executed in {(t2-t1):.4f}s')\n",
        "\n",
        "train_annotations.to_csv('training_annotations.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CH4244Assignment2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
